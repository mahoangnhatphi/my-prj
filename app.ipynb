{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahoangnhatphi/prj/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8kqk-0bdNQS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Y1SOPwdNvG"
      },
      "source": [
        "Step 0: Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3LqVFKsdQpu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5tybxxcp2IK",
        "outputId": "78c716d2-87f4-42ae-8e55-90e1b5d02b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading dog images\n",
            "downloading human images\n",
            "There are 13233 total human images.\n",
            "There are 8351 total dog images.\n",
            "CPU times: user 13.7 s, sys: 7.39 s, total: 21.1 s\n",
            "Wall time: 40.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
        "# https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip\n",
        "\n",
        "import requests, zipfile, io, os, shutil\n",
        "\n",
        "root = '/content'\n",
        "dogimages_url = \"https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\"\n",
        "humanimages_url = \"https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip\"\n",
        "\n",
        "data_path = os.path.join(root,'data')\n",
        "dogimages_path = os.path.join(data_path,'dogImages')\n",
        "humanimages_path = os.path.join(data_path,'lfw')\n",
        "data_path = os.path.join(root,'data')\n",
        "if not os.path.exists(data_path): os.mkdir(data_path)\n",
        "\n",
        "# if os.path.exists(dogimages_path):shutil.rmtree(dogimages_path)\n",
        "# if os.path.exists(humanimages_path):shutil.rmtree(humanimages_path)\n",
        "\n",
        "if not os.path.exists(dogimages_path):\n",
        "  print(\"downloading dog images\")\n",
        "  r = requests.get(dogimages_url)\n",
        "  z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "  z.extractall(data_path)\n",
        "\n",
        "if not os.path.exists(humanimages_path):\n",
        "  print(\"downloading human images\")\n",
        "  r = requests.get(humanimages_url)\n",
        "  z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "  z.extractall(data_path)\n",
        "\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# load filenames for human and dog images\n",
        "human_files = np.array(glob(\"/content/data/lfw/*/*\"))\n",
        "dog_files = np.array(glob(\"/content/data/dogImages/*/*/*\"))\n",
        "\n",
        "# print number of images in each dataset\n",
        "print('There are %d total human images.' % len(human_files))\n",
        "print('There are %d total dog images.' % len(dog_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHTIp55EdV9G",
        "outputId": "d95e4719-0232-462f-d5a6-54815c58d416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-01 16:27:17--  https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 676709 (661K) [text/plain]\n",
            "Saving to: ‘/content/haarcascades/haarcascade_frontalface_alt.xml’\n",
            "\n",
            "/content/haarcascad 100%[===================>] 660.85K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-09-01 16:27:17 (19.4 MB/s) - ‘/content/haarcascades/haarcascade_frontalface_alt.xml’ saved [676709/676709]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists('/content/haarcascades'): os.mkdir('/content/haarcascades')\n",
        "haarcascades_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml'\n",
        "!wget -O /content/haarcascades/haarcascade_frontalface_alt.xml {haarcascades_url}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Ubjm_rdh42"
      },
      "source": [
        "Step 1: Detect Dogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoQ0gXp0dli5"
      },
      "outputs": [],
      "source": [
        "# Write a Dog Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c__Cz5bTd1du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10738410-1860-4ae1-b56f-ce861a530ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 194MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Obtain Pre-trained VGG-16 Model\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# define VGG16 model\n",
        "VGG16 = models.vgg16(pretrained=True)\n",
        "\n",
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# move model to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    VGG16 = VGG16.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v_9IoitdwkW",
        "outputId": "68790720-7fcb-4ea7-d5ec-002af591faae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "def VGG16_predict(img_path):\n",
        "    '''\n",
        "    Use pre-trained VGG-16 model to obtain index corresponding to\n",
        "    predicted ImageNet class for image at specified path\n",
        "\n",
        "    Args:\n",
        "        img_path: path to an image\n",
        "\n",
        "    Returns:\n",
        "        Index corresponding to VGG-16 model's prediction\n",
        "    '''\n",
        "\n",
        "    ## TODO: Complete the function.\n",
        "    ## Load and pre-process an image from the given img_path\n",
        "    ## Return the *index* of the predicted class for that image\n",
        "\n",
        "    # data transformation\n",
        "    batch_size = 64\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    image_transforms = transforms.Compose([\n",
        "                            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "                            transforms.RandomRotation(degrees=15),\n",
        "                            transforms.ColorJitter(),\n",
        "                            transforms.RandomHorizontalFlip(),\n",
        "                            transforms.CenterCrop(size=224),  # Image net standards\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                 [0.229, 0.224, 0.225])  # Imagenet standards\n",
        "                        ])\n",
        "\n",
        "    image = image_transforms(img)[:3,:,:].unsqueeze(0)\n",
        "#     image = image_transforms(img)\n",
        "#     print(image_transformation)\n",
        "\n",
        "    if use_cuda:\n",
        "        image = image.cuda()\n",
        "    output = VGG16(image)\n",
        "\n",
        "    _,pred = torch.max(output, dim=1)\n",
        "    pred=pred.cpu()\n",
        "    pred = pred.data.numpy()[0]\n",
        "\n",
        "    return pred # predicted class index\n",
        "\n",
        "VGG16_predict(dog_files[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO9z0j54doNw",
        "outputId": "cfa8b4b2-b365-4b28-ad7a-a63481cea70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "### returns \"True\" if a dog is detected in the image stored at img_path\n",
        "def dog_detector(img_path):\n",
        "    ## TODO: Complete the function.\n",
        "#     in VGG16 index 151 to 268 are dog classifications\n",
        "\n",
        "    return VGG16_predict(img_path)>= 151 and VGG16_predict(img_path)<=268 # true/false\n",
        "\n",
        "print(dog_detector(dog_files[7]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlsfXrN_d9if"
      },
      "source": [
        "Assess the Dog Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "CS8MsYhOeCp2",
        "outputId": "21a8c74d-586b-4725-9b11-17fe1a29bba9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6f74b94be784>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhuman_files_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdog_files_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman_files_short\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdog_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman_files_short\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mhuman_files_count\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'human_files_short' is not defined"
          ]
        }
      ],
      "source": [
        "### TODO: Test the performance of the dog_detector function\n",
        "### on the images in human_files_short and dog_files_short.\n",
        "\n",
        "human_files_count=0\n",
        "dog_files_count=0\n",
        "for i in range(len(human_files_short)):\n",
        "    if dog_detector(human_files_short[i]):\n",
        "        human_files_count+=1\n",
        "    if dog_detector(dog_files_short[i]):\n",
        "        dog_files_count+=1\n",
        "print(\"number of dog faces detected in human_fiiles_short {0}\".format(human_files_count))\n",
        "print(\"number of dog faces detected in dog_files_short {0}\".format(dog_files_count))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKcHQv45eHvm",
        "outputId": "d477f812-2e8a-4ef2-bc47-638e4e27d29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6680 images belonging to 133 classes.\n",
            "Found 835 images belonging to 133 classes.\n",
            "Found 836 images belonging to 133 classes.\n"
          ]
        }
      ],
      "source": [
        "# CNN\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_path = '/content/data/dogImages/train/'\n",
        "val_path = '/content/data/dogImages/valid'\n",
        "test_path = '/content/data/dogImages/test'\n",
        "\n",
        "batch_size=64\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        # '/content/cats_dogs/data/train',  # this is the target directory\n",
        "        target_size=(150, 150),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        val_path,\n",
        "        # '/content/cats_dogs/data/val',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        # '/content/cats_dogs/data/val',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IzZdoWpgeLpv"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), input_shape=( 150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "# model.add(Conv2D(64, (3, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(133))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Okg63Vg5ePi2"
      },
      "outputs": [],
      "source": [
        "# Specify Loss Function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxwYeiyyeXvG"
      },
      "source": [
        "Train and Validate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7hDYjUCeb_o",
        "outputId": "1193d1f6-e20a-4756-e61c-2e70d7524461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-919974f827fb>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "105/105 [==============================] - 548s 5s/step - loss: 4.8924 - accuracy: 0.0081 - val_loss: 4.8857 - val_accuracy: 0.0108\n",
            "Epoch 2/16\n",
            " 74/105 [====================>.........] - ETA: 2:38 - loss: 4.8805 - accuracy: 0.0094"
          ]
        }
      ],
      "source": [
        "start_time = time()\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        #steps_per_epoch=18631 // batch_size,\n",
        "        epochs=16,\n",
        "        validation_data=validation_generator,\n",
        "        #validation_steps=10119 // batch_size\n",
        "        )\n",
        "model.save_weights('first_try.h5')\n",
        "\n",
        "print('time taken ',time()-start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW0AN6mweeIX"
      },
      "source": [
        "Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1uOJyyJeeuH"
      },
      "outputs": [],
      "source": [
        "# test_prediction = model.predict(test_generator)\n",
        "model.metrics_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH_ZKw5AeglX"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "# model.evaluate_generator(test_generator)\n",
        "test_generator.reset()\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_eval = model.evaluate_generator(test_generator,STEP_SIZE_TEST)\n",
        "print('test loss ',test_eval[0])\n",
        "print('test accuracy ',test_eval[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN to classfiy dog breeds"
      ],
      "metadata": {
        "id": "aV0AEYIJpsen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Specify data loaders\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_path = '/content/data/dogImages/train/'\n",
        "val_path = '/content/data/dogImages/valid'\n",
        "test_path = '/content/data/dogImages/test'\n",
        "\n",
        "batch_size=64\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        # '/content/cats_dogs/data/train',  # this is the target directory\n",
        "        target_size=(150, 150),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        val_path,\n",
        "        # '/content/cats_dogs/data/val',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        # '/content/cats_dogs/data/val',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "8D9T9jGuslP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
        "import keras\n",
        "keras.backend.set_learning_phase(1)\n",
        "\n",
        "img_rows, img_cols, img_channel = 150, 150, 3\n",
        "base_model = PTModel(weights='imagenet'\n",
        "                     ,include_top=False, input_shape=(img_rows, img_cols, img_channel), classes = 2)\n",
        "add_model = Sequential()\n",
        "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "add_model.add(Dense(64, activation='relu'))\n",
        "add_model.add(Dense(133, activation='sigmoid'))\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "    if layer.name.startswith('bn'):\n",
        "        layer.call(layer.input, training=False)"
      ],
      "metadata": {
        "id": "9lZ5dPH1prao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7d2Wii0bsdMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_point_name = 'vgg16.model'\n",
        "model_weights = 'vgg16.h5'\n",
        "\n",
        "start_time = time()\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=2,\n",
        "        validation_data=validation_generator,\n",
        "        #class_weight = class_weights,\n",
        "        callbacks=[ModelCheckpoint(check_point_name, monitor='val_acc', save_best_only=True)])\n",
        "model.save_weights(model_weights)\n",
        "\n",
        "print('time taken ',time()-start_time)"
      ],
      "metadata": {
        "id": "IhXLC0IDsodm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)\n",
        "test_generator.reset()\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_eval = model.evaluate_generator(test_generator,STEP_SIZE_TEST)\n",
        "print('test loss ',test_eval[0])\n",
        "print('test accuracy ',test_eval[1])"
      ],
      "metadata": {
        "id": "N4RmKpposqW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Write a function that takes a path to an image as input\n",
        "### and returns the dog breed that is predicted by the model.\n",
        "\n",
        "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
        "# class_names = [item[4:].replace(\"_\", \" \") for item in data_transfer['train'].classes]\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage import transform\n",
        "\n",
        "def load(filename):\n",
        "   np_image = Image.open(filename)\n",
        "   np_image = np.array(np_image).astype('float32')/255\n",
        "   np_image = transform.resize(np_image, (150, 150, 3))\n",
        "   np_image = np.expand_dims(np_image, axis=0)\n",
        "   return np_image\n",
        "\n",
        "def predict_breed_transfer(img_path):\n",
        "    # load the image and return the predicted breed\n",
        "  image = load(img_path)\n",
        "  y_prob = model.predict(image)\n",
        "  y_class = y_prob.argmax(axis=-1)\n",
        "  # print(y_classes)\n",
        "  labels = (train_generator.class_indices)\n",
        "  labels = dict((v,k) for k,v in labels.items())\n",
        "  prediction = [labels[k] for k in y_class]\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "_ARPtewnst9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your Algorithm"
      ],
      "metadata": {
        "id": "JFnbToFwszPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Write your algorithm.\n",
        "### Feel free to use as many code cells as needed.\n",
        "\n",
        "def run_app(img_path):\n",
        "    ## handle cases for a human face, dog, and neither\n",
        "    if dog_detector(img_path):\n",
        "      print('hello dog')\n",
        "      prediction = predict_breed_transfer(img_path)\n",
        "      print(prediction)\n",
        "    else:\n",
        "      print(\"couldn't detect dog or human image\")\n",
        "\n"
      ],
      "metadata": {
        "id": "02bY7OdXszzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dog_files[:3]"
      ],
      "metadata": {
        "id": "Uv7W0zUis7Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Execute your algorithm from Step 6 on\n",
        "## at least 6 images on your computer.\n",
        "## Feel free to use as many code cells as needed.\n",
        "\n",
        "## suggested code, below\n",
        "for file in np.hstack((human_files[:3], dog_files[:3])):\n",
        "    run_app(file)"
      ],
      "metadata": {
        "id": "Bo_lK28us8un"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNprhKBvA31Upd2P53eSiob",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}